# PTalker: Personalized Speech-Driven 3D Talking Head Animation via Style Disentanglement and Modality Alignment
The official repository of the paper [PTalker: Personalized Speech-Driven 3D Talking Head Animation via Style Disentanglement and Modality Alignment](https://arxiv.org/abs/)

<p align='center'>
  <b>
    <a href="">Paper</a>
    | 
    <a href="http://acmmm25p.bwbwiwn.site/">Project Page</a>
    |
    <a href="https://github.com/rrusereeuser/PTalker">Code</a> 
  </b>
</p> 

<!-- Colab notebook demonstration: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Egq0_ZK5sJAAawShxC0y4JRZQuVS2X-Z?usp=sharing) -->

  <p align='center'>  
    <img src='/paper_images/PTalker.svg' width='1000'/>
  </p>

Given a speech signal as input, our framework <strong>PTalker</strong> can generate stylized and realistic 3D talking head animtions through the <strong>(Style Disentanglement)</strong> and <strong>Modality Alignment</strong> modules.

## Demos
- Please click the Project Page.

## TODO
- [x] **Release Arxiv paper.**
- [x] **Release Project Page.**
- [ ] **Release code. (Once the paper is accepted)**
- [ ] **Release Pre-trained Model. (Once the paper is accepted)**



## Citation	

```
@article{2025ptalker,
  title={PTalker: Personalized Speech-Driven 3D Talking Head Animation via Style Disentanglement and Modality Alignment},
  author={},
  year={2025},
  eprint={},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}
```


## Acknowledgement
<!-- Some code are borrowed from following projects:
* [TalkingStyle](https://github.com/wangxuanx/TalkingStyle/)
* [FaceFormer](https://github.com/EvelynFan/FaceFormer/)
* [CodeTalker](https://github.com/Doubiiu/CodeTalker/)
 -->

The README.md template is borrowed from [SyncTalk](https://github.com/ziqiaopeng/SyncTalk)


Thanks for these great projects.

